# Owl_System
今后要做的飞行器与机器人所统用的一套控制体系的项目集合。

## Owl_home（上位机）

### Owl_home1.1

尝试基于Pyqt开发的串口调参显示上位机，性能还不咋地。可以用在其他项目。

## The_Owl(机器人设备)

### Owl_balcar

学习项目平衡车，没什么太大新意。

### EVA00/EAV02

应对24电赛的零号机。

| 装载       | 参数             |
| ---------- | ---------------- |
| 轴距       | 330mm            |
| 电机       | 1400kv           |
| 桨         | 8045             |
| 电池       | 2200mah 45c 3s   |
| 飞控       | 匿名拓空者p2飞控 |
| 机载电脑   | 香橙派5 pro      |
| 深度摄像头 | 无               |
| 激光雷达   | N10p             |

##### Q1：在不依靠光流的情况下，我们应该采用何种定位方案？

已知：大面积纯色块光流失效，SLAM定位（雷达方案，深度相机方案），UWB



##### Q2：是否采用激光雷达？

已知：高功率，360雷达高价格



##### Q3：如果采用深度摄像头，我们应该采用哪一款摄像头？（T265,D435,D435i）

已知：二手市场，D435i独立IMU，D435,D435i依赖机载电脑算力，T265停产

------

###### 资料：

- **Intel RealSense T265**
  - **优势**：内置视觉惯性SLAM（VIO）算法，直接输出6自由度位姿数据，无需依赖主机算力。其搭载的Movidius VPU可在1.5W低功耗下运行，适合无人机等对续航敏感的移动设备。
  - **适用场景**：快速定位需求（如避障、导航）、无需深度信息的纯位姿输出场景。例如，无人机飞控直接使用T265输出的位姿数据，可简化开发流程15。
  - **局限性**：无法提供深度数据，需搭配D400系列相机（如D435i）才能实现三维环境感知。
- **Intel RealSense D435i**
  - **优势**：提供RGB-D数据（深度+彩色图像），支持自定义SLAM算法（如ORB-SLAM2、VINS-Fusion）。内置IMU可实现多传感器融合，适合需要环境建模或复杂路径规划的无人机应用。
  - **适用场景**：需要自主建图、避障或高精度三维重建的无人机任务（如巡检、测绘）。例如，结合RGB-D数据实现动态障碍物检测。
  - **局限性**：依赖主机算力处理SLAM算法，对无人机机载计算单元性能要求较高。

- **优先选择T265的情况**：
  - 需快速部署且对功耗敏感，如竞速无人机或室内定位场景。
  - 无需深度信息，仅依赖位姿数据进行导航（如搭配光流传感器）。
- **优先选择D435i的情况**：
  - 需要环境感知与深度数据，如自主避障、三维地图构建。
  - 开发自定义SLAM算法或研究多传感器融合技术

------

##### 最终选择：

​	仅使用n10p激光雷达SLAM进行辅助定位，配合普通摄像头进行任务。

#### 拓空者p2飞控代码解读

​	首先明确我们的需求，需要修改飞控程序的哪些地方。

- 与机载电脑之间的数据传输

- 飞机自主飞行，雷达定点定位（PID）

- 视觉识别跟踪

  此时我们再整理整理需要改动和参考的地方。

##### 1.任务调度器 Ano_Scheduler.c

​	飞控的所有程序都基于这个调度器来跑，我们要研究的是如何往里面添加我们自己的任务程序。具体的实现方式很值得探讨，然而，然而。

​	例如：

```c
/* Ano_Scheduler.c */

static void Loop_100Hz(void)	//10ms执行一次
{
			test_rT[0]= GetSysTime_us ();
//////////////////////////////////////////////////////////////////////				
	/*遥控器数据处理*/
	RC_duty_task(10);
	
	/*飞行模式设置任务*/
	Flight_Mode_Set(10);
	
	//
	GPS_Data_Processing_Task(10);
	
	/*高度速度环控制*/
	Alt_1level_Ctrl(10e-3f);
	
	/*高度环控制*/
	Alt_2level_Ctrl(10e-3f);
	
	/*匿名光流状态检测*/	
	AnoOF_Check_State(0.01f);//AnoOF_DataAnl_Task(10);

	/*灯光控制*/	
	LED_Task2(10);
//////////////////////////////////////////////////////////////////////		
			test_rT[1]= GetSysTime_us ();
			test_rT[2] = (u32)(test_rT[1] - test_rT[0]) ;	
				
}
```

​	我们需要做的就是在相应的周期程序里添加我们自己的Task。

​	这里我大体写一个任务模板

```c
void My_Task(u8 dT_ms)
{
    static u16 timtmp = 0;			// 定时变量，在某些需要时间t的情况下使用
    if(Condition){					// 这里填入相应启动执行条件，例如遥控器某通道值处于特定值
    	timtmp += dT_ms;      		// 累加计时
     	Program();					// 执行相应程序
    }
}
```

#### 定位思路

​	通过雷达获取一定的（x，y）坐标：

​	*已知：cartography建图算法暂时调节有缺陷，获取的坐标并不是绝对的，偏差较大。在高速情况下，地图跑飞。*

**方案：**

1. 利用低速时位置较为准确，在飞行时停止建图，在期望静止时启动建图定位。飞控获取位置坐标，输入当前位置，期望位置pid调节输出xy方向飞行速度。

2. 在飞行时停止建图，在期望静止时启动建图定位。飞控获取位置坐标，对其微分得到速度，输入速度，期望速度pid调节输出xy方向飞行速度。

3. 飞行时一直建图，飞控获取位置坐标，对其微分得到速度，输入速度，期望速度pid调节输出xy方向飞行速度。

4. 飞行时一直建图，机载电脑处理位置坐标得到速度，输入给飞控，输入速度，期望速度pid调节输出xy方向飞行速度。

5. 飞行时一直建图，获取速度，动态控制cartography的运动滤波参数，提高建图效果。

   ------

   ​	以方案一，我们的可运算平台是飞控和机载电脑，任务流程应该在哪个平台上跑值得商榷。目前倾向于在机载电脑上进行任务流程。

   ​	机载电脑给予飞控需要移动的距离，两种方式：雷达微调移动控制，直接移动控制。

   **直接移动控制**

   ​	直接通过程控函数速度对时间积分。

   ```c
   
   ```

   

   ```python
   # 防止位置跳变
   # 渐变式启停
   def smooth_mapping_switch(is_moving):
       if is_moving:
           cartographer.set_scan_matching_enabled(False)  # 先禁用匹配
           rospy.sleep(0.5)  # 等待0.5s
           cartographer.pause_mapping()  # 再暂停建图
       else:
           cartographer.resume_mapping()
           rospy.sleep(1.0)  # 等待稳定
           cartographer.set_scan_matching_enabled(True)
   ```

   

